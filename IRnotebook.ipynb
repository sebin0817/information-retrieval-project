{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fasttext import FastVector\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import os, glob, re, sys, random, unicodedata, collections\n",
    "from tqdm import tqdm\n",
    "from functools import reduce\n",
    "import nltk\n",
    "from collections import Counter\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.tokenize import sent_tokenize , word_tokenize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word vectors from wiki.en.vec\n"
     ]
    }
   ],
   "source": [
    "eng_dictionary = FastVector(vector_file='wiki.en.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word vectors from wiki.de.vec\n"
     ]
    }
   ],
   "source": [
    "ger_dictionary = FastVector(vector_file='wiki.de.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading word vectors from wiki.fr.vec\n"
     ]
    }
   ],
   "source": [
    "fre_dictionary = FastVector(vector_file='wiki.fr.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from https://stackoverflow.com/questions/21030391/how-to-normalize-array-numpy\n",
    "def normalized(a, axis=-1, order=2):\n",
    "    \"\"\"Utility function to normalize the rows of a numpy array.\"\"\"\n",
    "    l2 = np.atleast_1d(np.linalg.norm(a, order, axis))\n",
    "    l2[l2==0] = 1\n",
    "    return a / np.expand_dims(l2, axis)\n",
    "\n",
    "def make_training_matrices(source_dictionary, target_dictionary, bilingual_dictionary):\n",
    "    \"\"\"\n",
    "    Source and target dictionaries are the FastVector objects of\n",
    "    source/target languages. bilingual_dictionary is a list of \n",
    "    translation pair tuples [(source_word, target_word), ...].\n",
    "    \"\"\"\n",
    "    source_matrix = []\n",
    "    target_matrix = []\n",
    "\n",
    "    for (source, target) in bilingual_dictionary:\n",
    "        if source in source_dictionary and target in target_dictionary:\n",
    "            source_matrix.append(source_dictionary[source])\n",
    "            target_matrix.append(target_dictionary[target])\n",
    "\n",
    "    # return training matrices\n",
    "    return np.array(source_matrix), np.array(target_matrix)\n",
    "\n",
    "def learn_transformation(source_matrix, target_matrix, normalize_vectors=True):\n",
    "    \"\"\"\n",
    "    Source and target matrices are numpy arrays, shape\n",
    "    (dictionary_length, embedding_dimension). These contain paired\n",
    "    word vectors from the bilingual dictionary.\n",
    "    \"\"\"\n",
    "    # optionally normalize the training vectors\n",
    "    if normalize_vectors:\n",
    "        source_matrix = normalized(source_matrix)\n",
    "        target_matrix = normalized(target_matrix)\n",
    "\n",
    "    # perform the SVD\n",
    "    product = np.matmul(source_matrix.transpose(), target_matrix)\n",
    "    U, s, V = np.linalg.svd(product)\n",
    "\n",
    "    # return orthogonal transformation which aligns source language to the target\n",
    "    return np.matmul(U, V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_words = set(eng_dictionary.word2id.keys())\n",
    "ger_words = set(ger_dictionary.word2id.keys())\n",
    "fre_words = set(fre_dictionary.word2id.keys())\n",
    "overlap = list(eng_words & ger_words)\n",
    "overlap_fr_en = list(eng_words & fre_words)\n",
    "bilingual_dictionary = [(entry, entry) for entry in overlap]\n",
    "bilingual_dictionary_fr_en = [(entry, entry) for entry in overlap_fr_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.021914206256188045\n",
      "0.04893054014859706\n",
      "-0.019676202184651607\n"
     ]
    }
   ],
   "source": [
    "eng_vector = eng_dictionary[\"cow\"]\n",
    "fre_vector = fre_dictionary[\"vache\"]\n",
    "ger_vector = ger_dictionary[\"kuh\"]\n",
    "print(FastVector.cosine_similarity(ger_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, ger_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_matrix, target_matrix = make_training_matrices(ger_dictionary, eng_dictionary, bilingual_dictionary)\n",
    "transform = learn_transformation(source_matrix, target_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_dictionary.apply_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5374997100024727\n",
      "0.5894027260080437\n",
      "0.5092332499687048\n"
     ]
    }
   ],
   "source": [
    "eng_vector = eng_dictionary[\"cow\"]\n",
    "fre_vector = fre_dictionary[\"vache\"]\n",
    "ger_vector = ger_dictionary[\"kuh\"]\n",
    "print(FastVector.cosine_similarity(ger_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, ger_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_matrix_fr, target_matrix_fr = make_training_matrices(fre_dictionary, eng_dictionary, bilingual_dictionary_fr_en)\n",
    "transform = learn_transformation(source_matrix_fr, target_matrix_fr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_dictionary.apply_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5374997100024727\n",
      "0.5894027260080437\n",
      "0.5092332499687048\n"
     ]
    }
   ],
   "source": [
    "eng_vector = eng_dictionary[\"cow\"]\n",
    "fre_vector = fre_dictionary[\"vache\"]\n",
    "ger_vector = ger_dictionary[\"kuh\"]\n",
    "print(FastVector.cosine_similarity(ger_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, ger_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6232559990666015\n",
      "0.6797876352842969\n",
      "0.6651148554627178\n"
     ]
    }
   ],
   "source": [
    "eng_vector = eng_dictionary[\"city\"]\n",
    "fre_vector = fre_dictionary[\"ville\"]\n",
    "ger_vector = ger_dictionary[\"stadt\"]\n",
    "print(FastVector.cosine_similarity(ger_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, eng_vector))\n",
    "print(FastVector.cosine_similarity(fre_vector, ger_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame()\n",
    "with pd.read_json('livivo_medline_00.jsonl', lines=True, chunksize=10000,nrows = 2000000) as reader:\n",
    "    for chunk in reader:\n",
    "        dff = dff.append(chunk[['DBRECORDID','TITLE','ABSTRACT','LANGUAGE']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dff.columns:\n",
    "    dff[i]=dff[i].apply(lambda x: x[0] if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=dff[dff['TITLE'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ger = dff.query('LANGUAGE == \"ger\"')\n",
    "df_eng = dff.query('LANGUAGE == \"eng\"')\n",
    "df_fre = dff.query('LANGUAGE == \"fre\"')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vector_t = eng_dictionary[\"medication\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "fre_vector_t = fre_dictionary[\"m√©dicament\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_vector1 = ger_dictionary[\"sind\"]\n",
    "ger_vector2 = ger_dictionary[\"neue\"]\n",
    "ger_vector3 = ger_dictionary[\"medikamente\"]\n",
    "ger_vector4 = ger_dictionary[\"zu\"]\n",
    "ger_vector5 = ger_dictionary[\"teuer\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "ger_vector_t = ger_vector1+ger_vector2+ger_vector3+ger_vector4+ger_vector5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47819758667529366\n"
     ]
    }
   ],
   "source": [
    "print(FastVector.cosine_similarity(eng_vector_t, ger_vector_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42318397682401204\n"
     ]
    }
   ],
   "source": [
    "print(FastVector.cosine_similarity(fre_vector_t, ger_vector_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text,lang):\n",
    "    \"\"\"Make all necessary preprocessing of text: strip accents and punctuation, remove the words only contains digit\n",
    "    remove \\n, tokenize our text, convert to lower case, remove stop words and \n",
    "    words with less than 2 chars.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): Input text\n",
    "\n",
    "    Returns:\n",
    "    str: cleaned tokenized text\n",
    "\n",
    "   \"\"\"    \n",
    "    WORD_MIN_LENGTH = 2\n",
    "    STOP_WORDS = nltk.corpus.stopwords.words(lang)\n",
    "    text = re.sub(re.compile('\\n'),' ',text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [word.lower() for word in words]\n",
    "    words = [word for word in words if word not in STOP_WORDS and len(word) >= WORD_MIN_LENGTH]\n",
    "    words = [word for word in words if word.isdigit()==False]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_ger=(df_ger[\"TITLE\"].apply(lambda x: tokenize_text(x,'german')))\n",
    "tokenized_eng=(df_eng[\"TITLE\"].apply(lambda x: tokenize_text(x,'english')))\n",
    "tokenized_fre=(df_fre[\"TITLE\"].apply(lambda x: tokenize_text(x,'french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list_query = [ger_dictionary[item] for item in [\"herzkatheter\"] if item in ger_dictionary]\n",
    "vecsum_query = np.sum(vec_list_query,axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = []\n",
    "ind = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Uni Mannheim\\IR\\Project\\fasttext.py:143: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.dot(vec_a, vec_b) / \\\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for ix, token_docs in enumerate(tokenized_ger):\n",
    "    ind.append(tokenized_ger.index[ix])\n",
    "    vec_list_doc = [ger_dictionary[item]\n",
    "                    for item in token_docs if item in ger_dictionary]\n",
    "    vecsum_doc = np.sum(vec_list_doc, axis=0)\n",
    "    cosine_sim.append(\n",
    "        FastVector.cosine_similarity(vecsum_query, vecsum_doc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ix, token_docs in enumerate(tokenized_eng):\n",
    "    ind.append(tokenized_eng.index[ix])\n",
    "    vec_list_doc = [eng_dictionary[item]\n",
    "                    for item in token_docs if item in eng_dictionary]\n",
    "    vecsum_doc = np.sum(vec_list_doc, axis=0)\n",
    "    cosine_sim.append(\n",
    "        FastVector.cosine_similarity(vecsum_query, vecsum_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ix, token_docs in enumerate(tokenized_fre):\n",
    "    ind.append(tokenized_fre.index[ix])\n",
    "    vec_list_doc = [fre_dictionary[item]\n",
    "                    for item in token_docs if item in fre_dictionary]\n",
    "    vecsum_doc = np.sum(vec_list_doc, axis=0)\n",
    "    cosine_sim.append(\n",
    "        FastVector.cosine_similarity(vecsum_query, vecsum_doc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim1 = [x if isinstance(x, float) else 0 for x in cosine_sim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBRECORDID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159864</th>\n",
       "      <td>M997705</td>\n",
       "      <td>Ein Prozessrechnersystem f√ºr Herzkatheterlabor...</td>\n",
       "      <td>In cooperation with the Department of Electron...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636928</th>\n",
       "      <td>M461773</td>\n",
       "      <td>Komplikationen ven√∂ser Verweilkatheter im Thor...</td>\n",
       "      <td>The increasing use of central venous catheters...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707523</th>\n",
       "      <td>M1546486</td>\n",
       "      <td>Komplikationen zentralven√∂ser Katheter bei Pat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123132</th>\n",
       "      <td>M960927</td>\n",
       "      <td>Lebervenographie mit Ballonkatheter nach porto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324162</th>\n",
       "      <td>M142043</td>\n",
       "      <td>Pr√§operative Nierenarterienblockade mit Ballon...</td>\n",
       "      <td>Renal artery occlusion with a balloon catheter...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596884</th>\n",
       "      <td>M1435805</td>\n",
       "      <td>Perkutane Silastic-Katheter bei Neu- und Fr√ºhg...</td>\n",
       "      <td>Background and methods!#!Central catheters are...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162129</th>\n",
       "      <td>M28321727</td>\n",
       "      <td>Wann zum Herzkatheter √ºberweisen?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130001</th>\n",
       "      <td>M967798</td>\n",
       "      <td>Lagebestimmung zentralven√∂ser Katheter durch i...</td>\n",
       "      <td>It is reported on the electrocardiographical m...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104242</th>\n",
       "      <td>M942036</td>\n",
       "      <td>Therapie bei Duraperforation mit Katheter w√§hr...</td>\n",
       "      <td>A rare complication following a dural tap in l...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234511</th>\n",
       "      <td>M1072590</td>\n",
       "      <td>Thrombektomie--chirurgische Therapie ven√∂ser T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705388</th>\n",
       "      <td>M1544351</td>\n",
       "      <td>Kollagenapplikation zum Verschluss der arterie...</td>\n",
       "      <td>Percutaneously introduced absorbable purified ...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925520</th>\n",
       "      <td>M1764589</td>\n",
       "      <td>Magnetresonanztomographie bei Patienten mit He...</td>\n",
       "      <td>Artificial valve prostheses are often regarded...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084060</th>\n",
       "      <td>M921842</td>\n",
       "      <td>Die Behandlung der Karotis-Kavernosus-Fistel m...</td>\n",
       "      <td>After a critical survey of the methods of trea...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307270</th>\n",
       "      <td>M124680</td>\n",
       "      <td>Karotis-Kavernosus-Fistel - Behandlung mit ein...</td>\n",
       "      <td>A relatively simple method for the intra-vascu...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311919</th>\n",
       "      <td>M129409</td>\n",
       "      <td>Erfahrungen mit einem lenkbaren Katheter in de...</td>\n",
       "      <td>Despite certain disadvantages, depending partl...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794202</th>\n",
       "      <td>M1633205</td>\n",
       "      <td>Die Reanimation von Patienten mit dem kardiopu...</td>\n",
       "      <td>The use of cardiopulmonary bypass within the f...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>669595</th>\n",
       "      <td>M494449</td>\n",
       "      <td>Transurethrale Elektroresektion bei Patienten ...</td>\n",
       "      <td>Transurethral electro-resection of prostate an...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926275</th>\n",
       "      <td>M1765344</td>\n",
       "      <td>Kardiologische Diagnostik bei arteriellen Embo...</td>\n",
       "      <td>Potential cardiac sources of arterial embolism...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670835</th>\n",
       "      <td>M1509797</td>\n",
       "      <td>Linksventrikul√§re Katheterablation des AV-Uber...</td>\n",
       "      <td>We report on a 32-year-old female patient with...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357368</th>\n",
       "      <td>M1196077</td>\n",
       "      <td>Behandlung mit Kathetern bei peripheren arteri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DBRECORDID                                              TITLE  \\\n",
       "1159864    M997705  Ein Prozessrechnersystem f√ºr Herzkatheterlabor...   \n",
       "636928     M461773  Komplikationen ven√∂ser Verweilkatheter im Thor...   \n",
       "1707523   M1546486  Komplikationen zentralven√∂ser Katheter bei Pat...   \n",
       "1123132    M960927  Lebervenographie mit Ballonkatheter nach porto...   \n",
       "324162     M142043  Pr√§operative Nierenarterienblockade mit Ballon...   \n",
       "1596884   M1435805  Perkutane Silastic-Katheter bei Neu- und Fr√ºhg...   \n",
       "162129   M28321727                  Wann zum Herzkatheter √ºberweisen?   \n",
       "1130001    M967798  Lagebestimmung zentralven√∂ser Katheter durch i...   \n",
       "1104242    M942036  Therapie bei Duraperforation mit Katheter w√§hr...   \n",
       "1234511   M1072590  Thrombektomie--chirurgische Therapie ven√∂ser T...   \n",
       "1705388   M1544351  Kollagenapplikation zum Verschluss der arterie...   \n",
       "1925520   M1764589  Magnetresonanztomographie bei Patienten mit He...   \n",
       "1084060    M921842  Die Behandlung der Karotis-Kavernosus-Fistel m...   \n",
       "307270     M124680  Karotis-Kavernosus-Fistel - Behandlung mit ein...   \n",
       "311919     M129409  Erfahrungen mit einem lenkbaren Katheter in de...   \n",
       "1794202   M1633205  Die Reanimation von Patienten mit dem kardiopu...   \n",
       "669595     M494449  Transurethrale Elektroresektion bei Patienten ...   \n",
       "1926275   M1765344  Kardiologische Diagnostik bei arteriellen Embo...   \n",
       "1670835   M1509797  Linksventrikul√§re Katheterablation des AV-Uber...   \n",
       "1357368   M1196077  Behandlung mit Kathetern bei peripheren arteri...   \n",
       "\n",
       "                                                  ABSTRACT LANGUAGE  \n",
       "1159864  In cooperation with the Department of Electron...      ger  \n",
       "636928   The increasing use of central venous catheters...      ger  \n",
       "1707523                                                NaN      ger  \n",
       "1123132                                                NaN      ger  \n",
       "324162   Renal artery occlusion with a balloon catheter...      ger  \n",
       "1596884  Background and methods!#!Central catheters are...      ger  \n",
       "162129                                                 NaN      ger  \n",
       "1130001  It is reported on the electrocardiographical m...      ger  \n",
       "1104242  A rare complication following a dural tap in l...      ger  \n",
       "1234511                                                NaN      ger  \n",
       "1705388  Percutaneously introduced absorbable purified ...      ger  \n",
       "1925520  Artificial valve prostheses are often regarded...      ger  \n",
       "1084060  After a critical survey of the methods of trea...      ger  \n",
       "307270   A relatively simple method for the intra-vascu...      ger  \n",
       "311919   Despite certain disadvantages, depending partl...      ger  \n",
       "1794202  The use of cardiopulmonary bypass within the f...      ger  \n",
       "669595   Transurethral electro-resection of prostate an...      ger  \n",
       "1926275  Potential cardiac sources of arterial embolism...      ger  \n",
       "1670835  We report on a 32-year-old female patient with...      ger  \n",
       "1357368                                                NaN      ger  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.loc[[x for _,x in sorted(zip(cosine_sim1,ind))][::-1][:20]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = dff.query('DBRECORDID==[\"NLM100935395\", \"M28321727\", \"M22396211\", \"M26182251\", \"M27855450\", \"M27371084\", \"M17668771\", \"M15526640\", \"M12116571\", \"M17619416\", \"M15373101\", \"M17327990\", \"M17036952\", \"M12619228\", \"M17036953\", \"M10766551\", \"M15832754\", \"M12661441\", \"M11862798\", \"M12014270\", \"M9274293\", \"M15526639\", \"M15295687\", \"M14534866\", \"M14534865\", \"M11847881\", \"M17287946\", \"M11367987\", \"M16685628\", \"M15884497\", \"M6768988\", \"M11349619\", \"M4408140\", \"M3699648\", \"M10719459\", \"M5033568\", \"M4341201\", \"M5994901\", \"M5171652\", \"M7670011\", \"M572445\", \"M13674380\", \"M822301\", \"M13095574\", \"M31938804\", \"M5811151\", \"M530728\", \"M530727\", \"M530726\", \"M6015202\", \"M172696\", \"M13153044\", \"M4779158\", \"M5537878\", \"M7268345\", \"M5381164\", \"M13325698\", \"M530725\", \"M14128579\", \"M14271658\", \"M14943165\", \"M28382405\", \"NLM101607162\", \"M27903031\", \"M29623382\", \"NLM101237723\", \"M31828657\", \"M32865509\", \"M28711420\", \"M18726641\", \"M31379065\", \"M23212601\", \"M22160954\", \"M25612278\", \"M32291683\", \"M33055148\", \"M31191628\", \"M33518405\", \"M29335976\", \"M13137320\", \"NLM100888962\", \"M31227510\", \"M32983409\", \"M30874757\", \"M18447284\", \"M32737488\", \"M11565209\", \"M32165421\", \"M32350102\", \"M22454204\", \"M30928352\", \"M32543896\", \"M31133083\", \"M31211489\", \"M30253970\", \"M32511272\", \"M17290313\", \"M32127268\", \"M17334121\", \"M32964247\"]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBRECORDID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21456</th>\n",
       "      <td>M28382405</td>\n",
       "      <td>Notfallmanagement im Herzkatheterlabor : Wenn ...</td>\n",
       "      <td>The establishment of primary percutaneous inte...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162129</th>\n",
       "      <td>M28321727</td>\n",
       "      <td>Wann zum Herzkatheter √ºberweisen?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354635</th>\n",
       "      <td>M172696</td>\n",
       "      <td>Herzkatheter bei Fallot' Tetralogie. Bericht e...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705860</th>\n",
       "      <td>M530725</td>\n",
       "      <td>Das Risiko der Herzkatheter-Untersuchung. Eine...</td>\n",
       "      <td>A retrospective study is undertaken in order t...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705861</th>\n",
       "      <td>M530726</td>\n",
       "      <td>Das Risiko der Herzkatheter-Untersuchung. Eine...</td>\n",
       "      <td>The author reviewed the complications of 700 h...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705862</th>\n",
       "      <td>M530728</td>\n",
       "      <td>Das Risiko der Herzkatheter-Untersuchung. Eine...</td>\n",
       "      <td>The review of 700 heart catheterizations in in...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705863</th>\n",
       "      <td>M530727</td>\n",
       "      <td>Das Risiko der Herzkatheter-Untersuchung. Eine...</td>\n",
       "      <td>Disturbances of heart rhythm, observed during ...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747551</th>\n",
       "      <td>M572445</td>\n",
       "      <td>Heparinisierung w√§hrend transven√∂ser Herzkathe...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984828</th>\n",
       "      <td>M822301</td>\n",
       "      <td>Einfluss von Herzkatheter-untersuchung und Ang...</td>\n",
       "      <td>The serum activities of LDH, alpha-HBDH, CK, G...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       DBRECORDID                                              TITLE  \\\n",
       "21456   M28382405  Notfallmanagement im Herzkatheterlabor : Wenn ...   \n",
       "162129  M28321727                  Wann zum Herzkatheter √ºberweisen?   \n",
       "354635    M172696  Herzkatheter bei Fallot' Tetralogie. Bericht e...   \n",
       "705860    M530725  Das Risiko der Herzkatheter-Untersuchung. Eine...   \n",
       "705861    M530726  Das Risiko der Herzkatheter-Untersuchung. Eine...   \n",
       "705862    M530728  Das Risiko der Herzkatheter-Untersuchung. Eine...   \n",
       "705863    M530727  Das Risiko der Herzkatheter-Untersuchung. Eine...   \n",
       "747551    M572445  Heparinisierung w√§hrend transven√∂ser Herzkathe...   \n",
       "984828    M822301  Einfluss von Herzkatheter-untersuchung und Ang...   \n",
       "\n",
       "                                                 ABSTRACT LANGUAGE  \n",
       "21456   The establishment of primary percutaneous inte...      ger  \n",
       "162129                                                NaN      ger  \n",
       "354635                                                NaN      ger  \n",
       "705860  A retrospective study is undertaken in order t...      ger  \n",
       "705861  The author reviewed the complications of 700 h...      ger  \n",
       "705862  The review of 700 heart catheterizations in in...      ger  \n",
       "705863  Disturbances of heart rhythm, observed during ...      ger  \n",
       "747551                                                NaN      ger  \n",
       "984828  The serum activities of LDH, alpha-HBDH, CK, G...      ger  "
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverted_index(words):\n",
    "    \"\"\"Create a inverted index of words (tokens or terms) from a list of terms\n",
    "\n",
    "    Parameters:\n",
    "    words (list of str): tokenized document text\n",
    "\n",
    "    Returns:\n",
    "    Inverted index of document (dict)\n",
    "\n",
    "   \"\"\"\n",
    "    inverted = {}\n",
    "    for index, word in enumerate(words):\n",
    "        locations = inverted.setdefault(word, [])\n",
    "        locations.append(index)\n",
    "    return inverted\n",
    "\n",
    "\n",
    "def inverted_index_add(inverted, doc_id, doc_index):\n",
    "    \"\"\"Insert document id into Inverted Index\n",
    "\n",
    "    Parameters:\n",
    "    inverted (dict): Inverted Index\n",
    "    doc_id (int): Id of document been added\n",
    "    doc_index (dict): Inverted Index of a specific document.\n",
    "\n",
    "    Returns:\n",
    "    Inverted index of document (dict)\n",
    "\n",
    "   \"\"\"\n",
    "    for word in doc_index.keys():\n",
    "        locations = doc_index[word]\n",
    "        indices = inverted.setdefault(word, {})\n",
    "        indices[doc_id] = locations\n",
    "    return inverted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388570\n"
     ]
    }
   ],
   "source": [
    "inverted_doc_indexes_english = {}\n",
    "files_with_index_english = []\n",
    "files_with_tokens_english = {}\n",
    "for i in tokenized_eng.index:\n",
    "    #Clean and Tokenize text of each document\n",
    "    words = tokenized_eng[i]\n",
    "    #Store tokens\n",
    "    files_with_tokens_english[i] = words\n",
    "\n",
    "    doc_index = inverted_index(words)\n",
    "    inverted_index_add(inverted_doc_indexes_english, i, doc_index)\n",
    "    files_with_index_english.append(i)\n",
    "########################################\n",
    "DF_english = {}\n",
    "for word in inverted_doc_indexes_english.keys():\n",
    "    DF_english[word] = len ([doc for doc in inverted_doc_indexes_english[word]])\n",
    "\n",
    "total_vocab_size_english = len(DF_english)\n",
    "print(total_vocab_size_english)\n",
    "########################################\n",
    "idf_english = {} # Our data structure to store Tf-Idf weights\n",
    "\n",
    "N = len(files_with_tokens_english)\n",
    "\n",
    "for doc_id in tokenized_eng.index:\n",
    "    tokens= tokenized_eng[doc_id]\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "    \n",
    "    for token in np.unique(tokens):        \n",
    "        # Calculate Idf\n",
    "        if token in DF_english:\n",
    "            df = DF_english[token]\n",
    "        else:\n",
    "            df = 0\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        # Calculate Tf-idf        \n",
    "        idf_english[token] = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139895\n"
     ]
    }
   ],
   "source": [
    "inverted_doc_indexes_german = {}\n",
    "files_with_index_german = []\n",
    "files_with_tokens_german = {}\n",
    "for i in tokenized_ger.index:\n",
    "    #Clean and Tokenize text of each document\n",
    "    words = tokenized_ger[i]\n",
    "    #Store tokens\n",
    "    files_with_tokens_german[i] = words\n",
    "\n",
    "    doc_index = inverted_index(words)\n",
    "    inverted_index_add(inverted_doc_indexes_german, i, doc_index)\n",
    "    files_with_index_german.append(i)\n",
    "\n",
    "################################\n",
    "DF_german = {}\n",
    "for word in inverted_doc_indexes_german.keys():\n",
    "    DF_german[word] = len ([doc for doc in inverted_doc_indexes_german[word]])\n",
    "\n",
    "total_vocab_size_german = len(DF_german)\n",
    "print(total_vocab_size_german)\n",
    "######################\n",
    "idf_german = {} # Our data structure to store Tf-Idf weights\n",
    "\n",
    "N = len(files_with_tokens_german)\n",
    "\n",
    "for doc_id in tokenized_ger.index:\n",
    "    tokens= tokenized_ger[doc_id]\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "    \n",
    "    for token in np.unique(tokens):        \n",
    "        # Calculate Idf\n",
    "        if token in DF_german:\n",
    "            df = DF_german[token]\n",
    "        else:\n",
    "            df = 0\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        # Calculate Tf-idf        \n",
    "        idf_german[token] = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61734\n"
     ]
    }
   ],
   "source": [
    "inverted_doc_indexes_french = {}\n",
    "files_with_index_french = []\n",
    "files_with_tokens_french = {}\n",
    "for i in tokenized_fre.index:\n",
    "    #Clean and Tokenize text of each document\n",
    "    words = tokenized_fre[i]\n",
    "    #Store tokens\n",
    "    files_with_tokens_french[i] = words\n",
    "\n",
    "    doc_index = inverted_index(words)\n",
    "    inverted_index_add(inverted_doc_indexes_french, i, doc_index)\n",
    "    files_with_index_french.append(i)\n",
    "\n",
    "################################\n",
    "DF_french = {}\n",
    "for word in inverted_doc_indexes_french.keys():\n",
    "    DF_french[word] = len ([doc for doc in inverted_doc_indexes_french[word]])\n",
    "\n",
    "total_vocab_size_french = len(DF_french)\n",
    "print(total_vocab_size_french)\n",
    "######################\n",
    "idf_french = {} # Our data structure to store Tf-Idf weights\n",
    "\n",
    "N = len(files_with_tokens_french)\n",
    "\n",
    "for doc_id in tokenized_fre.index:\n",
    "    tokens= tokenized_fre[doc_id]\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "    \n",
    "    for token in np.unique(tokens):        \n",
    "        # Calculate Idf\n",
    "        if token in DF_french:\n",
    "            df = DF_french[token]\n",
    "        else:\n",
    "            df = 0\n",
    "        idf = np.log((N+1)/(df+1))\n",
    "        \n",
    "        # Calculate Tf-idf        \n",
    "        idf_french[token] = idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim2 = []\n",
    "ind2 = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Uni Mannheim\\IR\\Project\\fasttext.py:143: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.dot(vec_a, vec_b) / \\\n"
     ]
    }
   ],
   "source": [
    "for ix, token_docs in enumerate(tokenized_ger):\n",
    "    ind2.append(tokenized_ger.index[ix])\n",
    "    vec_list_doc2 = [idf_german[item]*ger_dictionary[item]\n",
    "                    for item in token_docs if item in ger_dictionary]\n",
    "    vecsum_doc2 = np.sum(vec_list_doc2, axis=0)\n",
    "    cosine_sim2.append(\n",
    "        FastVector.cosine_similarity(vecsum_query, vecsum_doc2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, token_docs in enumerate(tokenized_eng):\n",
    "    ind2.append(tokenized_eng.index[ix])\n",
    "    vec_list_doc2 = [idf_english[item]*eng_dictionary[item]\n",
    "                     for item in token_docs if item in eng_dictionary]\n",
    "    vecsum_doc2 = np.sum(vec_list_doc2, axis=0)\n",
    "    cosine_sim2.append(\n",
    "        FastVector.cosine_similarity(vecsum_query, vecsum_doc2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ix, token_docs in enumerate(tokenized_fre):\n",
    "    ind2.append(tokenized_fre.index[ix])\n",
    "    vec_list_doc2 = [idf_french[item]*fre_dictionary[item]\n",
    "                     for item in token_docs if item in fre_dictionary]\n",
    "    vecsum_doc2 = np.sum(vec_list_doc2, axis=0)\n",
    "    cosine_sim2.append(\n",
    "        FastVector.cosine_similarity(vecsum_query, vecsum_doc2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim3 = [x if isinstance(x, float) else 0 for x in cosine_sim2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DBRECORDID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ABSTRACT</th>\n",
       "      <th>LANGUAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1159864</th>\n",
       "      <td>M997705</td>\n",
       "      <td>Ein Prozessrechnersystem f√ºr Herzkatheterlabor...</td>\n",
       "      <td>In cooperation with the Department of Electron...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636928</th>\n",
       "      <td>M461773</td>\n",
       "      <td>Komplikationen ven√∂ser Verweilkatheter im Thor...</td>\n",
       "      <td>The increasing use of central venous catheters...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084060</th>\n",
       "      <td>M921842</td>\n",
       "      <td>Die Behandlung der Karotis-Kavernosus-Fistel m...</td>\n",
       "      <td>After a critical survey of the methods of trea...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307270</th>\n",
       "      <td>M124680</td>\n",
       "      <td>Karotis-Kavernosus-Fistel - Behandlung mit ein...</td>\n",
       "      <td>A relatively simple method for the intra-vascu...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162129</th>\n",
       "      <td>M28321727</td>\n",
       "      <td>Wann zum Herzkatheter √ºberweisen?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1707523</th>\n",
       "      <td>M1546486</td>\n",
       "      <td>Komplikationen zentralven√∂ser Katheter bei Pat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123132</th>\n",
       "      <td>M960927</td>\n",
       "      <td>Lebervenographie mit Ballonkatheter nach porto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596884</th>\n",
       "      <td>M1435805</td>\n",
       "      <td>Perkutane Silastic-Katheter bei Neu- und Fr√ºhg...</td>\n",
       "      <td>Background and methods!#!Central catheters are...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324162</th>\n",
       "      <td>M142043</td>\n",
       "      <td>Pr√§operative Nierenarterienblockade mit Ballon...</td>\n",
       "      <td>Renal artery occlusion with a balloon catheter...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104242</th>\n",
       "      <td>M942036</td>\n",
       "      <td>Therapie bei Duraperforation mit Katheter w√§hr...</td>\n",
       "      <td>A rare complication following a dural tap in l...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705388</th>\n",
       "      <td>M1544351</td>\n",
       "      <td>Kollagenapplikation zum Verschluss der arterie...</td>\n",
       "      <td>Percutaneously introduced absorbable purified ...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357368</th>\n",
       "      <td>M1196077</td>\n",
       "      <td>Behandlung mit Kathetern bei peripheren arteri...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234511</th>\n",
       "      <td>M1072590</td>\n",
       "      <td>Thrombektomie--chirurgische Therapie ven√∂ser T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1925520</th>\n",
       "      <td>M1764589</td>\n",
       "      <td>Magnetresonanztomographie bei Patienten mit He...</td>\n",
       "      <td>Artificial valve prostheses are often regarded...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917743</th>\n",
       "      <td>M742699</td>\n",
       "      <td>Herzbeuteltamponade nach Ventrikelperforation ...</td>\n",
       "      <td>Two cases of cardiac tamponade after perforati...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670835</th>\n",
       "      <td>M1509797</td>\n",
       "      <td>Linksventrikul√§re Katheterablation des AV-Uber...</td>\n",
       "      <td>We report on a 32-year-old female patient with...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996721</th>\n",
       "      <td>M834459</td>\n",
       "      <td>Indikation zur Herzkatheteruntersuchung bei an...</td>\n",
       "      <td>This brief report shows that the age for absol...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311919</th>\n",
       "      <td>M129409</td>\n",
       "      <td>Erfahrungen mit einem lenkbaren Katheter in de...</td>\n",
       "      <td>Despite certain disadvantages, depending partl...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1926275</th>\n",
       "      <td>M1765344</td>\n",
       "      <td>Kardiologische Diagnostik bei arteriellen Embo...</td>\n",
       "      <td>Potential cardiac sources of arterial embolism...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130001</th>\n",
       "      <td>M967798</td>\n",
       "      <td>Lagebestimmung zentralven√∂ser Katheter durch i...</td>\n",
       "      <td>It is reported on the electrocardiographical m...</td>\n",
       "      <td>ger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DBRECORDID                                              TITLE  \\\n",
       "1159864    M997705  Ein Prozessrechnersystem f√ºr Herzkatheterlabor...   \n",
       "636928     M461773  Komplikationen ven√∂ser Verweilkatheter im Thor...   \n",
       "1084060    M921842  Die Behandlung der Karotis-Kavernosus-Fistel m...   \n",
       "307270     M124680  Karotis-Kavernosus-Fistel - Behandlung mit ein...   \n",
       "162129   M28321727                  Wann zum Herzkatheter √ºberweisen?   \n",
       "1707523   M1546486  Komplikationen zentralven√∂ser Katheter bei Pat...   \n",
       "1123132    M960927  Lebervenographie mit Ballonkatheter nach porto...   \n",
       "1596884   M1435805  Perkutane Silastic-Katheter bei Neu- und Fr√ºhg...   \n",
       "324162     M142043  Pr√§operative Nierenarterienblockade mit Ballon...   \n",
       "1104242    M942036  Therapie bei Duraperforation mit Katheter w√§hr...   \n",
       "1705388   M1544351  Kollagenapplikation zum Verschluss der arterie...   \n",
       "1357368   M1196077  Behandlung mit Kathetern bei peripheren arteri...   \n",
       "1234511   M1072590  Thrombektomie--chirurgische Therapie ven√∂ser T...   \n",
       "1925520   M1764589  Magnetresonanztomographie bei Patienten mit He...   \n",
       "917743     M742699  Herzbeuteltamponade nach Ventrikelperforation ...   \n",
       "1670835   M1509797  Linksventrikul√§re Katheterablation des AV-Uber...   \n",
       "996721     M834459  Indikation zur Herzkatheteruntersuchung bei an...   \n",
       "311919     M129409  Erfahrungen mit einem lenkbaren Katheter in de...   \n",
       "1926275   M1765344  Kardiologische Diagnostik bei arteriellen Embo...   \n",
       "1130001    M967798  Lagebestimmung zentralven√∂ser Katheter durch i...   \n",
       "\n",
       "                                                  ABSTRACT LANGUAGE  \n",
       "1159864  In cooperation with the Department of Electron...      ger  \n",
       "636928   The increasing use of central venous catheters...      ger  \n",
       "1084060  After a critical survey of the methods of trea...      ger  \n",
       "307270   A relatively simple method for the intra-vascu...      ger  \n",
       "162129                                                 NaN      ger  \n",
       "1707523                                                NaN      ger  \n",
       "1123132                                                NaN      ger  \n",
       "1596884  Background and methods!#!Central catheters are...      ger  \n",
       "324162   Renal artery occlusion with a balloon catheter...      ger  \n",
       "1104242  A rare complication following a dural tap in l...      ger  \n",
       "1705388  Percutaneously introduced absorbable purified ...      ger  \n",
       "1357368                                                NaN      ger  \n",
       "1234511                                                NaN      ger  \n",
       "1925520  Artificial valve prostheses are often regarded...      ger  \n",
       "917743   Two cases of cardiac tamponade after perforati...      ger  \n",
       "1670835  We report on a 32-year-old female patient with...      ger  \n",
       "996721   This brief report shows that the age for absol...      ger  \n",
       "311919   Despite certain disadvantages, depending partl...      ger  \n",
       "1926275  Potential cardiac sources of arterial embolism...      ger  \n",
       "1130001  It is reported on the electrocardiographical m...      ger  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.loc[[x for _,x in sorted(zip(cosine_sim3,ind2))][::-1][:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - implement 2 approaches \n",
    "\n",
    "1 translate query to english\n",
    "2 detect query language and use that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de\n"
     ]
    }
   ],
   "source": [
    "# %pip install googletrans==4.0.0-rc1\n",
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Compile all Word Embeddings in a dictionary\n",
    "all_dict = {\"de\": ger_dictionary,\n",
    "            \"en\": eng_dictionary,\n",
    "            \"fr\": fre_dictionary}\n",
    "\n",
    "# all_dict = {\"de\": {\"stadt\":1}, # For testing\n",
    "#             \"en\": {\"city\":2},\n",
    "#             \"fr\": {\"ville\":3}}\n",
    "\n",
    "q = \"stadt\"\n",
    "\n",
    "# Approach 1\n",
    "q_eng = translator.translate(q).text\n",
    "q_eng_vector = eng_dictionary[q_eng]\n",
    "\n",
    "# Approach 2\n",
    "q_lang = translator.detect(q).lang\n",
    "q_lang_vector = all_dict[q_lang][q]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c754d8008c5f8560e4adf341ebf96f62d30db323e3ac43f60a1cb4dab6d757"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
